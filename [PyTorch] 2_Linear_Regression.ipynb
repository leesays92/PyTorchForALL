{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<center><font size='5'><b>Deep Learning for All_pytorch</b></font><br><br><font size='5'>Chap2. Linear Regression<b></b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data, Weight, biases 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight과 Bias를 0으로 초기화 -> 항상 출력 0으로 예측\n",
    "# requires_grad = True : 학습할 것이라고 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "hypothesis = x_train*W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable을 사용한 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = Variable(torch.zeros(1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute loss \n",
    "\n",
    "### Mean Squared Error(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "- torch.optim 라이브러리 사용\n",
    "  - [W,b]는 학습할 tensor들\n",
    "  - lr은 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W,b], lr=0.01)\n",
    "\n",
    "\n",
    "#######################항상 붙어다니는 3줄##############################\n",
    "optimizer.zero_grad() # Gradient 초기화\n",
    "cost.backward() # backward로 gradient 계산\n",
    "optimizer.step() # step()으로 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총정리 \n",
    "\n",
    "- 한번만\n",
    "  - 데이터 정의, hypothesis 초기화, optimizer 정의\n",
    "- iteration\n",
    "  - Hypothesis 예측, cost 계산, optimizer로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
      "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
      "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
      "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
      "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
      "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
      "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
      "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
      "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
      "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
      "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7078], requires_grad=True)\n",
      "tensor([0.6515], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD 직접 구현해 보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/10 W: 0.000, Cost: 4.666667\n",
      "Epoch    2/10 W: 1.400, Cost: 0.746666\n",
      "Epoch    3/10 W: 0.840, Cost: 0.119467\n",
      "Epoch    4/10 W: 1.064, Cost: 0.019115\n",
      "Epoch    5/10 W: 0.974, Cost: 0.003058\n",
      "Epoch    6/10 W: 1.010, Cost: 0.000489\n",
      "Epoch    7/10 W: 0.996, Cost: 0.000078\n",
      "Epoch    8/10 W: 1.002, Cost: 0.000013\n",
      "Epoch    9/10 W: 0.999, Cost: 0.000002\n",
      "Epoch   10/10 W: 1.000, Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[1],[2],[3]])\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1)\n",
    "\n",
    "# learning rate 설정\n",
    "lr = 0.1\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train*W\n",
    "    \n",
    "    # cost gradient 계산\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    gradient = torch.sum((W*x_train - y_train) * x_train)\n",
    "    \n",
    "    print('Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}'.format(epoch, n_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    # cost gradient로 H(x) update\n",
    "    W -= lr * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level Implementation with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 __init__에서는 사용할 레이어들을 정의하게 된다. \n",
    "- forward에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3905],\n",
      "        [ 0.1615],\n",
      "        [-0.0676]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE로 cost 구하기\n",
    "\n",
    "cost = F.mse_loss(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientDescent\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 1.008, b: -0.590 Cost: 0.406030\n",
      "Epoch  100/1000 W: 1.172, b: -0.391 Cost: 0.022032\n",
      "Epoch  200/1000 W: 1.135, b: -0.307 Cost: 0.013615\n",
      "Epoch  300/1000 W: 1.106, b: -0.242 Cost: 0.008413\n",
      "Epoch  400/1000 W: 1.084, b: -0.190 Cost: 0.005199\n",
      "Epoch  500/1000 W: 1.066, b: -0.149 Cost: 0.003212\n",
      "Epoch  600/1000 W: 1.052, b: -0.117 Cost: 0.001985\n",
      "Epoch  700/1000 W: 1.041, b: -0.092 Cost: 0.001227\n",
      "Epoch  800/1000 W: 1.032, b: -0.073 Cost: 0.000758\n",
      "Epoch  900/1000 W: 1.025, b: -0.057 Cost: 0.000468\n",
      "Epoch 1000/1000 W: 1.020, b: -0.045 Cost: 0.000289\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "# 모델 초기화\n",
    "model = LinearRegressionModel()\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/48466625/61097625-f68d0f00-a496-11e9-8495-0b9244c96a2a.png)\n",
    "\n",
    "$H(x) = w_1x_1 + w_2x_2 + w_3x_3 + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "                            [93,88,93],\n",
    "                            [89,91,80],\n",
    "                            [96,98,100],\n",
    "                            [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight, biases 초기화\n",
    "W = torch.zeros((3,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 설정\n",
    "\n",
    "optimizer = torch.optim.SGD([W,b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 W: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]), Cost: 322.482056\n",
      "Epoch    1/20 W: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]), Cost: 107.717064\n",
      "Epoch    2/20 W: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]), Cost: 38.687500\n",
      "Epoch    3/20 W: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]), Cost: 16.499043\n",
      "Epoch    4/20 W: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]), Cost: 9.365657\n",
      "Epoch    5/20 W: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]), Cost: 7.071114\n",
      "Epoch    6/20 W: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]), Cost: 6.331847\n",
      "Epoch    7/20 W: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]), Cost: 6.092532\n",
      "Epoch    8/20 W: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]), Cost: 6.013817\n",
      "Epoch    9/20 W: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]), Cost: 5.986785\n",
      "Epoch   10/20 W: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]), Cost: 5.976325\n",
      "Epoch   11/20 W: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]), Cost: 5.971208\n",
      "Epoch   12/20 W: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]), Cost: 5.967835\n",
      "Epoch   13/20 W: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]), Cost: 5.964969\n",
      "Epoch   14/20 W: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]), Cost: 5.962291\n",
      "Epoch   15/20 W: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]), Cost: 5.959664\n",
      "Epoch   16/20 W: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]), Cost: 5.957089\n",
      "Epoch   17/20 W: tensor([154.0543, 185.1140, 175.7470, 198.6150, 141.2166]), Cost: 5.954494\n",
      "Epoch   18/20 W: tensor([154.0546, 185.1143, 175.7486, 198.6150, 141.2171]), Cost: 5.951927\n",
      "Epoch   19/20 W: tensor([154.0547, 185.1143, 175.7500, 198.6147, 141.2173]), Cost: 5.949370\n",
      "Epoch   20/20 W: tensor([154.0546, 185.1142, 175.7512, 198.6143, 141.2175]), Cost: 5.946793\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    # Cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    # cost로 H(x) 업데이트\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} W: {}, Cost: {:.6f}'.format(epoch, n_epochs, hypothesis.squeeze().detach(), cost.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 입력차원은 3이고 출력차원은 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) # hypothesis 계산을 어떻게 할지 알려주는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost: 14229.998047\n",
      "Epoch    1/20 Cost: 4460.848633\n",
      "Epoch    2/20 Cost: 1398.737671\n",
      "Epoch    3/20 Cost: 438.928680\n",
      "Epoch    4/20 Cost: 138.079956\n",
      "Epoch    5/20 Cost: 43.779396\n",
      "Epoch    6/20 Cost: 14.221448\n",
      "Epoch    7/20 Cost: 4.956458\n",
      "Epoch    8/20 Cost: 2.052372\n",
      "Epoch    9/20 Cost: 1.142069\n",
      "Epoch   10/20 Cost: 0.856727\n",
      "Epoch   11/20 Cost: 0.767262\n",
      "Epoch   12/20 Cost: 0.739204\n",
      "Epoch   13/20 Cost: 0.730392\n",
      "Epoch   14/20 Cost: 0.727615\n",
      "Epoch   15/20 Cost: 0.726716\n",
      "Epoch   16/20 Cost: 0.726412\n",
      "Epoch   17/20 Cost: 0.726307\n",
      "Epoch   18/20 Cost: 0.726243\n",
      "Epoch   19/20 Cost: 0.726196\n",
      "Epoch   20/20 Cost: 0.726168\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망에 사용할 데이터 생성\n",
    "\n",
    "def get_data(): ###### 입력과 출력 데이터로 구성된 Tensor 배열 제공\n",
    "    train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "    train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "    dtype = torch.FloatTensor\n",
    "    X = Variable(torch.from_numpy(train_X).type(dtype),requires_grad=False).view(17,1)\n",
    "    y = Variable(torch.from_numpy(train_Y).type(dtype),requires_grad=False)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 생성\n",
    "\n",
    "def get_weights(): #### 최적화할 파라미터 \n",
    "    w = Variable(torch.randn(1),requires_grad = True)\n",
    "    b = Variable(torch.randn(1),requires_grad=True)\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=17, out_features=1, bias=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치 신경망 구현 \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "f = nn.Linear(17,1) \n",
    "f\n",
    "\n",
    "# y_pred = torch.matmul(x,w)+b 보다 훨씬 단순해진 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data(Minibatch Gradient Descent에서)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 클래스\n",
    "\n",
    "- Dataset 클래스를 상속해 __사용자 정의 데이터셋 클래스를 만든다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self): # 데이터셋 클래스의 테이블 읽기 / 이미지 파일명 읽기와 같은 초기화 작업이 필요할때, 이 메서드에 구현하기\n",
    "        self.x_data = [[73,80,75],\n",
    "                      [93,88,93],\n",
    "                      [89,91,90],\n",
    "                      [96,98,100],\n",
    "                      [73,66,70]]\n",
    "        self.y_data = [[152],[185],[180],[196],[142]]\n",
    "        \n",
    "    def __len__(self): # 이 데이터셋의 총 데이터수를 반환\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx): #어떤 idx를 받았을때 그에 상응하는 입출력 데이터 반환 \n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "                              \n",
    "        return x, y\n",
    "    \n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 클래스\n",
    "\n",
    "- 배치로 만드는 작업을 돕는 유틸리티 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle=True) #가져올 데이터셋, 배치사이즈, 셔플 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate LR 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 입력차원은 3이고 출력차원은 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) # hypothesis 계산을 어떻게 할지 알려주는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 Batch 13 Cost: 37811.089844\n",
      "Epoch 0/20 Batch 23 Cost: 5945.278809\n",
      "Epoch 0/20 Batch 33 Cost: 1988.551514\n",
      "Epoch 1/20 Batch 13 Cost: 1036.760986\n",
      "Epoch 1/20 Batch 23 Cost: 314.877808\n",
      "Epoch 1/20 Batch 33 Cost: 124.283913\n",
      "Epoch 2/20 Batch 13 Cost: 32.047115\n",
      "Epoch 2/20 Batch 23 Cost: 13.070057\n",
      "Epoch 2/20 Batch 33 Cost: 0.095560\n",
      "Epoch 3/20 Batch 13 Cost: 5.376614\n",
      "Epoch 3/20 Batch 23 Cost: 0.353518\n",
      "Epoch 3/20 Batch 33 Cost: 1.954518\n",
      "Epoch 4/20 Batch 13 Cost: 1.698066\n",
      "Epoch 4/20 Batch 23 Cost: 2.195828\n",
      "Epoch 4/20 Batch 33 Cost: 0.568628\n",
      "Epoch 5/20 Batch 13 Cost: 1.189131\n",
      "Epoch 5/20 Batch 23 Cost: 1.036901\n",
      "Epoch 5/20 Batch 33 Cost: 2.770679\n",
      "Epoch 6/20 Batch 13 Cost: 2.777880\n",
      "Epoch 6/20 Batch 23 Cost: 1.978745\n",
      "Epoch 6/20 Batch 33 Cost: 0.049007\n",
      "Epoch 7/20 Batch 13 Cost: 1.866581\n",
      "Epoch 7/20 Batch 23 Cost: 1.647989\n",
      "Epoch 7/20 Batch 33 Cost: 0.740336\n",
      "Epoch 8/20 Batch 13 Cost: 1.209825\n",
      "Epoch 8/20 Batch 23 Cost: 0.416578\n",
      "Epoch 8/20 Batch 33 Cost: 2.941945\n",
      "Epoch 9/20 Batch 13 Cost: 0.485077\n",
      "Epoch 9/20 Batch 23 Cost: 0.990888\n",
      "Epoch 9/20 Batch 33 Cost: 4.641389\n",
      "Epoch 10/20 Batch 13 Cost: 2.702142\n",
      "Epoch 10/20 Batch 23 Cost: 1.401860\n",
      "Epoch 10/20 Batch 33 Cost: 0.053885\n",
      "Epoch 11/20 Batch 13 Cost: 0.926623\n",
      "Epoch 11/20 Batch 23 Cost: 2.555900\n",
      "Epoch 11/20 Batch 33 Cost: 0.383430\n",
      "Epoch 12/20 Batch 13 Cost: 1.163095\n",
      "Epoch 12/20 Batch 23 Cost: 2.014743\n",
      "Epoch 12/20 Batch 33 Cost: 0.419818\n",
      "Epoch 13/20 Batch 13 Cost: 1.526179\n",
      "Epoch 13/20 Batch 23 Cost: 0.184763\n",
      "Epoch 13/20 Batch 33 Cost: 3.351253\n",
      "Epoch 14/20 Batch 13 Cost: 2.561220\n",
      "Epoch 14/20 Batch 23 Cost: 0.384213\n",
      "Epoch 14/20 Batch 33 Cost: 0.761225\n",
      "Epoch 15/20 Batch 13 Cost: 1.431290\n",
      "Epoch 15/20 Batch 23 Cost: 1.619020\n",
      "Epoch 15/20 Batch 33 Cost: 0.274226\n",
      "Epoch 16/20 Batch 13 Cost: 1.725390\n",
      "Epoch 16/20 Batch 23 Cost: 1.601070\n",
      "Epoch 16/20 Batch 33 Cost: 0.626913\n",
      "Epoch 17/20 Batch 13 Cost: 0.343352\n",
      "Epoch 17/20 Batch 23 Cost: 2.537538\n",
      "Epoch 17/20 Batch 33 Cost: 0.238896\n",
      "Epoch 18/20 Batch 13 Cost: 1.116901\n",
      "Epoch 18/20 Batch 23 Cost: 1.777283\n",
      "Epoch 18/20 Batch 33 Cost: 0.253952\n",
      "Epoch 19/20 Batch 13 Cost: 1.645543\n",
      "Epoch 19/20 Batch 23 Cost: 2.229793\n",
      "Epoch 19/20 Batch 33 Cost: 0.214635\n",
      "Epoch 20/20 Batch 13 Cost: 1.773727\n",
      "Epoch 20/20 Batch 23 Cost: 0.226807\n",
      "Epoch 20/20 Batch 33 Cost: 2.764383\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader): #인덱스와 가져온 데이터를 받음\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        #hypothesis 계산\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        #cost계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        # cost로 hypothesis 업데이트\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {}/{} Batch {}{} Cost: {:6f}'.format(epoch, n_epochs, batch_idx+1, len(dataloader), cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
